{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "252421ac",
   "metadata": {},
   "source": [
    "# 多分类问题\n",
    "\n",
    "transforms是常用的图像预处理方法， 这个在torchvision计算机视觉工具包中，我们在安装Pytorch的时候顺便安装了这个torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4b03843",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955a184f",
   "metadata": {},
   "source": [
    "## pytorch的图像预处理 transforms\n",
    "\n",
    "transform的compose可以对图像进行一系列处理，  \n",
    "\n",
    "比如ToTensor可以将图像转变为多通道的张量 28x28 -> 1x28x28  \n",
    "\n",
    "Nomalize是进行每个像素的标准化 具体的代码掠过，本次主题是另一个任务"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ffb6c0a6",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 2 required positional arguments: 'mean' and 'std'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17120\\3083175099.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m transform = transforms.Compose([transforms.ToTensor(),\n\u001b[1;32m----> 2\u001b[1;33m                                transforms.Normalize()])\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: __init__() missing 2 required positional arguments: 'mean' and 'std'"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                               transforms.Normalize()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f756b9",
   "metadata": {},
   "source": [
    "## Otto Group Product Classification（重点）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be868697",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#首先将类别标签转化为id\n",
    "def lables2id(lables):\n",
    "        target_id = []\n",
    "        target_lables = ['Class_1', 'Class_2', 'Class_3', 'Class_4', 'Class_5', 'Class_6', 'Class_7', 'Class_8', 'Class_9']\n",
    "        for lable in lables:\n",
    "            target_id.append(target_lables.index(lable))\n",
    "        return target_id\n",
    "    \n",
    "    \n",
    "# 定义数据集类 这里用pandsa去读\n",
    "class ProductDataset(Dataset):\n",
    "    def __init__(self,filepath):\n",
    "        data = pd.read_csv(filepath)\n",
    "        lables = data['target']\n",
    "        self.len = data.shape[0] #多少行\n",
    "        \n",
    "        self.x_data = torch.tensor(np.array(data)[:,1:-1].astype(float))#这里突然脑抽了想了好久，切片-1，最后一列是不在里面的\n",
    "        self.y_data = lables2id(lables)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index], self.y_data[index]\n",
    " \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self,filepath):\n",
    "        data = pd.read_csv(filepath)\n",
    "        lables = data['target']\n",
    "        self.len = data.shape[0] #多少行\n",
    "        \n",
    "        self.x_data = torch.tensor(np.array(data)[:,1:-1].astype(float))#这里突然脑抽了想了好久，切片-1，最后一列是不在里面的\n",
    "        self.y_data = lables2id(lables)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index], self.y_data[index]\n",
    " \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "    \n",
    "train_dataset =ProductDataset('./train.csv')\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True, num_workers=0)\n",
    "\n",
    "#定义一个net\n",
    "\n",
    "class net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(net, self).__init__()\n",
    "        self.linear1 = torch.nn.Linear(93, 64)\n",
    "        self.linear2 = torch.nn.Linear(64, 32)\n",
    "        self.linear3 = torch.nn.Linear(32, 16)\n",
    "        self.linear4 = torch.nn.Linear(16, 9)\n",
    "        self.activate = torch.nn.ReLU()#这里\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.activate(self.linear1(x))\n",
    "        x = self.activate(self.linear2(x))\n",
    "        x = self.activate(self.linear3(x))\n",
    "        x = self.linear4(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = net()\n",
    "\n",
    "#定义损失函数和优化器\n",
    "criterion = torch.nn.CrossEntropyLoss()#用交叉熵\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5912b0a",
   "metadata": {},
   "source": [
    "这里涉及两个概念，momentun和relu激活函数。\n",
    "\n",
    "momenun真的很帅，简而言之就是确定梯度下降距离的时候要算上上一次梯度得到距离，可以看作是小球的惯性！！帅下一期我将学习并且整理所有优化器的原理  \n",
    "  \n",
    "  \n",
    "活函数来说，ReLU有以下优势：对于线性函数而言，ReLU的表达能力更强，尤其体现在深度网络中；而对于非线性函数而言，ReLU由于非负区间的梯度为常数，因此不存在梯度消失问题(Vanishing Gradient Problem)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74d76094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   300] loss: 1.046\n",
      "[1,   600] loss: 0.697\n",
      "[1,   900] loss: 0.656\n",
      "[2,   300] loss: 0.621\n",
      "[2,   600] loss: 0.607\n",
      "[2,   900] loss: 0.595\n",
      "[3,   300] loss: 0.570\n",
      "[3,   600] loss: 0.579\n",
      "[3,   900] loss: 0.558\n",
      "[4,   300] loss: 0.549\n",
      "[4,   600] loss: 0.539\n",
      "[4,   900] loss: 0.548\n",
      "[5,   300] loss: 0.518\n",
      "[5,   600] loss: 0.528\n",
      "[5,   900] loss: 0.528\n",
      "[6,   300] loss: 0.519\n",
      "[6,   600] loss: 0.506\n",
      "[6,   900] loss: 0.513\n",
      "[7,   300] loss: 0.494\n",
      "[7,   600] loss: 0.511\n",
      "[7,   900] loss: 0.499\n",
      "[8,   300] loss: 0.479\n",
      "[8,   600] loss: 0.501\n",
      "[8,   900] loss: 0.489\n",
      "[9,   300] loss: 0.471\n",
      "[9,   600] loss: 0.486\n",
      "[9,   900] loss: 0.488\n",
      "[10,   300] loss: 0.464\n",
      "[10,   600] loss: 0.479\n",
      "[10,   900] loss: 0.475\n",
      "[11,   300] loss: 0.463\n",
      "[11,   600] loss: 0.468\n",
      "[11,   900] loss: 0.472\n",
      "[12,   300] loss: 0.459\n",
      "[12,   600] loss: 0.451\n",
      "[12,   900] loss: 0.462\n",
      "[13,   300] loss: 0.458\n",
      "[13,   600] loss: 0.450\n",
      "[13,   900] loss: 0.457\n",
      "[14,   300] loss: 0.445\n",
      "[14,   600] loss: 0.448\n",
      "[14,   900] loss: 0.456\n",
      "[15,   300] loss: 0.451\n",
      "[15,   600] loss: 0.437\n",
      "[15,   900] loss: 0.448\n",
      "[16,   300] loss: 0.433\n",
      "[16,   600] loss: 0.439\n",
      "[16,   900] loss: 0.442\n",
      "[17,   300] loss: 0.435\n",
      "[17,   600] loss: 0.440\n",
      "[17,   900] loss: 0.442\n",
      "[18,   300] loss: 0.431\n",
      "[18,   600] loss: 0.432\n",
      "[18,   900] loss: 0.431\n",
      "[19,   300] loss: 0.424\n",
      "[19,   600] loss: 0.437\n",
      "[19,   900] loss: 0.428\n",
      "[20,   300] loss: 0.416\n",
      "[20,   600] loss: 0.432\n",
      "[20,   900] loss: 0.430\n",
      "[21,   300] loss: 0.424\n",
      "[21,   600] loss: 0.419\n",
      "[21,   900] loss: 0.429\n",
      "[22,   300] loss: 0.410\n",
      "[22,   600] loss: 0.427\n",
      "[22,   900] loss: 0.427\n",
      "[23,   300] loss: 0.413\n",
      "[23,   600] loss: 0.417\n",
      "[23,   900] loss: 0.426\n",
      "[24,   300] loss: 0.411\n",
      "[24,   600] loss: 0.411\n",
      "[24,   900] loss: 0.426\n",
      "[25,   300] loss: 0.409\n",
      "[25,   600] loss: 0.421\n",
      "[25,   900] loss: 0.413\n",
      "[26,   300] loss: 0.409\n",
      "[26,   600] loss: 0.410\n",
      "[26,   900] loss: 0.415\n",
      "[27,   300] loss: 0.400\n",
      "[27,   600] loss: 0.412\n",
      "[27,   900] loss: 0.420\n",
      "[28,   300] loss: 0.405\n",
      "[28,   600] loss: 0.400\n",
      "[28,   900] loss: 0.418\n",
      "[29,   300] loss: 0.408\n",
      "[29,   600] loss: 0.404\n",
      "[29,   900] loss: 0.404\n",
      "[30,   300] loss: 0.395\n",
      "[30,   600] loss: 0.415\n",
      "[30,   900] loss: 0.404\n",
      "[31,   300] loss: 0.398\n",
      "[31,   600] loss: 0.402\n",
      "[31,   900] loss: 0.402\n",
      "[32,   300] loss: 0.392\n",
      "[32,   600] loss: 0.405\n",
      "[32,   900] loss: 0.407\n",
      "[33,   300] loss: 0.399\n",
      "[33,   600] loss: 0.400\n",
      "[33,   900] loss: 0.402\n",
      "[34,   300] loss: 0.388\n",
      "[34,   600] loss: 0.395\n",
      "[34,   900] loss: 0.396\n",
      "[35,   300] loss: 0.387\n",
      "[35,   600] loss: 0.396\n",
      "[35,   900] loss: 0.399\n",
      "[36,   300] loss: 0.382\n",
      "[36,   600] loss: 0.391\n",
      "[36,   900] loss: 0.404\n",
      "[37,   300] loss: 0.384\n",
      "[37,   600] loss: 0.383\n",
      "[37,   900] loss: 0.406\n",
      "[38,   300] loss: 0.375\n",
      "[38,   600] loss: 0.395\n",
      "[38,   900] loss: 0.393\n",
      "[39,   300] loss: 0.379\n",
      "[39,   600] loss: 0.385\n",
      "[39,   900] loss: 0.396\n",
      "[40,   300] loss: 0.375\n",
      "[40,   600] loss: 0.390\n",
      "[40,   900] loss: 0.387\n",
      "[41,   300] loss: 0.382\n",
      "[41,   600] loss: 0.386\n",
      "[41,   900] loss: 0.388\n",
      "[42,   300] loss: 0.374\n",
      "[42,   600] loss: 0.385\n",
      "[42,   900] loss: 0.393\n",
      "[43,   300] loss: 0.380\n",
      "[43,   600] loss: 0.383\n",
      "[43,   900] loss: 0.386\n",
      "[44,   300] loss: 0.375\n",
      "[44,   600] loss: 0.389\n",
      "[44,   900] loss: 0.380\n",
      "[45,   300] loss: 0.382\n",
      "[45,   600] loss: 0.386\n",
      "[45,   900] loss: 0.380\n",
      "[46,   300] loss: 0.370\n",
      "[46,   600] loss: 0.382\n",
      "[46,   900] loss: 0.382\n",
      "[47,   300] loss: 0.370\n",
      "[47,   600] loss: 0.380\n",
      "[47,   900] loss: 0.382\n",
      "[48,   300] loss: 0.366\n",
      "[48,   600] loss: 0.377\n",
      "[48,   900] loss: 0.385\n",
      "[49,   300] loss: 0.372\n",
      "[49,   600] loss: 0.377\n",
      "[49,   900] loss: 0.380\n",
      "[50,   300] loss: 0.366\n",
      "[50,   600] loss: 0.384\n",
      "[50,   900] loss: 0.378\n",
      "[51,   300] loss: 0.369\n",
      "[51,   600] loss: 0.373\n",
      "[51,   900] loss: 0.382\n",
      "[52,   300] loss: 0.361\n",
      "[52,   600] loss: 0.374\n",
      "[52,   900] loss: 0.376\n",
      "[53,   300] loss: 0.360\n",
      "[53,   600] loss: 0.372\n",
      "[53,   900] loss: 0.381\n",
      "[54,   300] loss: 0.361\n",
      "[54,   600] loss: 0.369\n",
      "[54,   900] loss: 0.378\n",
      "[55,   300] loss: 0.363\n",
      "[55,   600] loss: 0.368\n",
      "[55,   900] loss: 0.377\n",
      "[56,   300] loss: 0.360\n",
      "[56,   600] loss: 0.370\n",
      "[56,   900] loss: 0.372\n",
      "[57,   300] loss: 0.370\n",
      "[57,   600] loss: 0.373\n",
      "[57,   900] loss: 0.364\n",
      "[58,   300] loss: 0.365\n",
      "[58,   600] loss: 0.363\n",
      "[58,   900] loss: 0.377\n",
      "[59,   300] loss: 0.362\n",
      "[59,   600] loss: 0.367\n",
      "[59,   900] loss: 0.373\n",
      "[60,   300] loss: 0.361\n",
      "[60,   600] loss: 0.362\n",
      "[60,   900] loss: 0.375\n",
      "[61,   300] loss: 0.361\n",
      "[61,   600] loss: 0.364\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3148\\3669536783.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m         \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3148\\3669536783.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(epoch)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mrunning_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    639\u001b[0m                                  \"https://pytorch.org/docs/stable/data.html#torch.utils.data.IterableDataset for examples.\")\n\u001b[0;32m    640\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwarn_msg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 641\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    642\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    643\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\autograd\\profiler.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, exc_type, exc_value, traceback)\u001b[0m\n\u001b[0;32m    491\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_type\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_value\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    492\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_callbacks_on_exit\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 493\u001b[1;33m             \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_record_function_exit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    494\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    495\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_call_end_callbacks_on_future\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfut\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mFuture\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mFuture\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\_ops.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    440\u001b[0m         \u001b[1;31m# We save the function ptr as the `op` attribute on\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    441\u001b[0m         \u001b[1;31m# OpOverloadPacket to access it here.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 442\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    443\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    444\u001b[0m     \u001b[1;31m# TODO: use this to make a __dir__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loss_list = []\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model.to(device)\n",
    "def train(epoch):\n",
    "    running_loss = 0.0\n",
    "    for batch_idx, data in enumerate(train_loader):\n",
    "        inputs, target = data\n",
    "        inputs,target = inputs.to(device),target.to(device)\n",
    "        inputs = inputs.float()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, target)\n",
    "        \n",
    "        loss_list.append(loss.item())\n",
    "\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if batch_idx % 300 == 299:  # 每300轮打印一次结果\n",
    "            print('[%d, %5d] loss: %.3f' % (epoch + 1, batch_idx + 1, running_loss / 300))\n",
    "            running_loss = 0.0\n",
    "            \n",
    "#开始训练         \n",
    "if __name__ == '__main__':\n",
    "    for epoch in range(500):\n",
    "        train(epoch)\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "#预测函数\n",
    "def predict_save():\n",
    "    with torch.no_grad():\n",
    "      test_data = pd.read_csv('./test.csv')\n",
    "      x_text = torch.tensor(np.array(test_data)[:, 1:].astype(float))\n",
    "      y_pred = model(x_text.float())\n",
    "      _, predicted = torch.max(y_pred, dim=1)  # 这里先取出最大概率的索引，即是所预测的类别。\n",
    "      out = pd.get_dummies(predicted)  # get_dummies 利用pandas实现one hot encode，方便保存为预测文件。\n",
    "\n",
    "      lables = ['Class_1', 'Class_2', 'Class_3', 'Class_4', 'Class_5', 'Class_6', 'Class_7', 'Class_8', 'Class_9']\n",
    "      # 添加列标签\n",
    "      out.columns = lables\n",
    "      # 插入id行\n",
    "      out.insert(0, 'id', test_data['id'])\n",
    "      result = pd.DataFrame(out)\n",
    "      result.to_csv('my_predict.csv', index=False)\n",
    "        \n",
    "        \n",
    "#predict_save()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a27e1b56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>feat_1</th>\n",
       "      <th>feat_2</th>\n",
       "      <th>feat_3</th>\n",
       "      <th>feat_4</th>\n",
       "      <th>feat_5</th>\n",
       "      <th>feat_6</th>\n",
       "      <th>feat_7</th>\n",
       "      <th>feat_8</th>\n",
       "      <th>feat_9</th>\n",
       "      <th>...</th>\n",
       "      <th>feat_84</th>\n",
       "      <th>feat_85</th>\n",
       "      <th>feat_86</th>\n",
       "      <th>feat_87</th>\n",
       "      <th>feat_88</th>\n",
       "      <th>feat_89</th>\n",
       "      <th>feat_90</th>\n",
       "      <th>feat_91</th>\n",
       "      <th>feat_92</th>\n",
       "      <th>feat_93</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144363</th>\n",
       "      <td>144364</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144364</th>\n",
       "      <td>144365</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144365</th>\n",
       "      <td>144366</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144366</th>\n",
       "      <td>144367</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144367</th>\n",
       "      <td>144368</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>144368 rows × 94 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  feat_1  feat_2  feat_3  feat_4  feat_5  feat_6  feat_7  \\\n",
       "0            1       0       0       0       0       0       0       0   \n",
       "1            2       2       2      14      16       0       0       0   \n",
       "2            3       0       1      12       1       0       0       0   \n",
       "3            4       0       0       0       1       0       0       0   \n",
       "4            5       1       0       0       1       0       0       1   \n",
       "...        ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "144363  144364       0       0       0       0       0       0       0   \n",
       "144364  144365       0       0       0       0       0       0       0   \n",
       "144365  144366       0       1       0       0       0       0       1   \n",
       "144366  144367       0       0       0       0       0       0       0   \n",
       "144367  144368       0       0       0       0       0       0       0   \n",
       "\n",
       "        feat_8  feat_9  ...  feat_84  feat_85  feat_86  feat_87  feat_88  \\\n",
       "0            0       0  ...        0        0       11        1       20   \n",
       "1            0       0  ...        0        0        0        0        0   \n",
       "2            0       0  ...        0        0        0        0        2   \n",
       "3            0       0  ...        0        3        1        0        0   \n",
       "4            2       0  ...        0        0        0        0        0   \n",
       "...        ...     ...  ...      ...      ...      ...      ...      ...   \n",
       "144363       0       0  ...        0        0        2        1        1   \n",
       "144364       0       0  ...        0        1        4        1       11   \n",
       "144365       1       0  ...        0        1        3        1        1   \n",
       "144366       0       0  ...        0        0        0        0        5   \n",
       "144367       0       0  ...        0        0        9        1        6   \n",
       "\n",
       "        feat_89  feat_90  feat_91  feat_92  feat_93  \n",
       "0             0        0        0        0        0  \n",
       "1             4        0        0        2        0  \n",
       "2             0        0        0        0        1  \n",
       "3             0        0        0        0        0  \n",
       "4             0        0        9        0        0  \n",
       "...         ...      ...      ...      ...      ...  \n",
       "144363        0        0        0        0        0  \n",
       "144364        0        0        0        0        0  \n",
       "144365        0        0        1        0        0  \n",
       "144366        0        0        0        1        0  \n",
       "144367        0        0        0        0        0  \n",
       "\n",
       "[144368 rows x 94 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('./test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e988281",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
